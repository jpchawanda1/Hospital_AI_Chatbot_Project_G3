{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee417bd",
   "metadata": {},
   "source": [
    "# Hospital AI Chatbot Backend - Professional Implementation\n",
    "\n",
    "This notebook implements a sophisticated AI-powered chatbot backend for hospital information systems. The system integrates advanced NLP techniques, machine learning, and reinforcement learning to provide intelligent responses about medical services, appointments, and hospital information.\n",
    "\n",
    "## Key Features:\n",
    "- **Advanced NLP**: Sentence Transformers for semantic understanding\n",
    "- **Machine Learning**: TF-IDF vectorization with cosine similarity\n",
    "- **Reinforcement Learning**: User feedback integration for continuous improvement\n",
    "- **Multi-modal Architecture**: Context-based + AI model responses\n",
    "- **Production Ready**: Flask API with comprehensive endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c5b5d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Loading all necessary dependencies for NLP, machine learning, web framework, and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd49256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "print(\"✓ Core libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135dd8b",
   "metadata": {},
   "source": [
    "## NLPEnhancedChatbot Class - Core Implementation\n",
    "\n",
    "The main chatbot class implementing advanced NLP techniques, machine learning algorithms, and reinforcement learning for intelligent medical information assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPEnhancedChatbot:\n",
    "    def __init__(self, csv_file_path=None):\n",
    "        self.qa_pairs = []\n",
    "        self.original_qa_count = 0  # Track original count for learning statistics\n",
    "        self.context_data = \"\"\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.model_type = \"Loading...\"\n",
    "        self.model_loading = True\n",
    "        \n",
    "        # ML/RL components\n",
    "        self.conversation_history = []\n",
    "        self.feedback_scores = {}\n",
    "        self.response_quality = {}\n",
    "        self.learning_rate = 0.1\n",
    "        self.vectorizer = None\n",
    "        self.qa_vectors = None\n",
    "        \n",
    "        # Advanced NLP components\n",
    "        self.sentence_transformer = None\n",
    "        self.nlp_processor = None\n",
    "        self.intent_classifier = None\n",
    "        self.context_embeddings = None\n",
    "        self.domain_knowledge = {}\n",
    "        \n",
    "        # Load Q&A data if available\n",
    "        if csv_file_path and os.path.exists(csv_file_path):\n",
    "            self.load_qa_data(csv_file_path)\n",
    "        \n",
    "        # Initialize NLP components\n",
    "        self.initialize_nlp_components()\n",
    "        \n",
    "        # Start model loading in background thread\n",
    "        self.model_loading_thread = threading.Thread(target=self.initialize_model, daemon=True)\n",
    "        self.model_loading_thread.start()\n",
    "        \n",
    "        print(\"✓ NLPEnhancedChatbot initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a9015",
   "metadata": {},
   "source": [
    "## Advanced NLP Components Initialization\n",
    "\n",
    "Setting up sophisticated NLP components including Sentence Transformers, intent classification, and semantic understanding capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def initialize_nlp_components(self):\n",
    "        \"\"\"Initialize advanced NLP components for semantic understanding\"\"\"\n",
    "        try:\n",
    "            print(\"Initializing advanced NLP components...\")\n",
    "            \n",
    "            # Initialize sentence transformer for semantic embeddings\n",
    "            self.initialize_sentence_transformer()\n",
    "            \n",
    "            # Initialize intent classification\n",
    "            self.initialize_intent_classifier()\n",
    "            \n",
    "            # Build domain knowledge from Q&A pairs\n",
    "            self.build_domain_knowledge()\n",
    "            \n",
    "            # Create semantic embeddings for existing data\n",
    "            if self.qa_pairs:\n",
    "                self.create_semantic_embeddings()\n",
    "            \n",
    "            print(\"✓ Advanced NLP components initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing NLP components: {e}\")\n",
    "            # Fallback to basic TF-IDF\n",
    "            self.initialize_fallback_ml()\n",
    "    \n",
    "    def initialize_sentence_transformer(self):\n",
    "        \"\"\"Initialize sentence transformer for semantic understanding\"\"\"\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            \n",
    "            # Use a lightweight but effective model\n",
    "            model_name = 'all-MiniLM-L6-v2'\n",
    "            print(f\"Loading sentence transformer: {model_name}\")\n",
    "            self.sentence_transformer = SentenceTransformer(model_name)\n",
    "            print(\"✓ Sentence transformer loaded successfully\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"⚠ sentence-transformers not available, using fallback\")\n",
    "            self.sentence_transformer = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sentence transformer: {e}\")\n",
    "            self.sentence_transformer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4d302",
   "metadata": {},
   "source": [
    "## Intent Classification System\n",
    "\n",
    "Implementing intelligent intent recognition for medical queries including appointments, pricing, emergency contacts, and hospital information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ec6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def initialize_intent_classifier(self):\n",
    "        \"\"\"Initialize intent classification for understanding user queries\"\"\"\n",
    "        try:\n",
    "            # Define common healthcare intents\n",
    "            self.intent_patterns = {\n",
    "                'appointment': ['appointment', 'book', 'schedule', 'visit', 'consultation', 'see doctor'],\n",
    "                'pricing': ['price', 'cost', 'how much', 'expensive', 'fee', 'charge', 'bill'],\n",
    "                'hospital_info': ['hours', 'visiting', 'location', 'address', 'directions', 'parking'],\n",
    "                'emergency': ['emergency', 'urgent', 'ambulance', '911', 'critical', 'accident'],\n",
    "                'departments': ['department', 'specialist', 'doctor', 'cardiology', 'neurology', 'oncology'],\n",
    "                'insurance': ['insurance', 'cover', 'nhif', 'payment', 'billing', 'claim'],\n",
    "                'medical_records': ['records', 'results', 'report', 'test', 'x-ray', 'lab'],\n",
    "                'symptoms': ['pain', 'fever', 'headache', 'chest', 'stomach', 'symptoms'],\n",
    "                'pharmacy': ['medicine', 'prescription', 'drug', 'pharmacy', 'medication'],\n",
    "                'general': ['hello', 'hi', 'greetings', 'thank you', 'bye', 'goodbye', 'help']\n",
    "            }\n",
    "            \n",
    "            print(\"✓ Intent classification patterns loaded\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing intent classifier: {e}\")\n",
    "    \n",
    "    def classify_intent(self, user_input):\n",
    "        \"\"\"Classify the intent of the user input\"\"\"\n",
    "        user_input_lower = user_input.lower()\n",
    "        intent_scores = {}\n",
    "        \n",
    "        for intent, patterns in self.intent_patterns.items():\n",
    "            score = 0\n",
    "            for pattern in patterns:\n",
    "                if pattern in user_input_lower:\n",
    "                    score += 1\n",
    "            intent_scores[intent] = score\n",
    "        \n",
    "        # Return the intent with highest score, or 'general' if no clear intent\n",
    "        if max(intent_scores.values()) > 0:\n",
    "            return max(intent_scores, key=intent_scores.get)\n",
    "        return 'general'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3902b19",
   "metadata": {},
   "source": [
    "## Data Loading and Vectorization\n",
    "\n",
    "Loading hospital Q&A data and creating machine learning vectors for semantic similarity matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_qa_data(self, file_path):\n",
    "        \"\"\"Load questions and answers from CSV file and create ML vectors\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                for row in reader:\n",
    "                    # Handle both old format (Question/Answer) and new format (question/answer)\n",
    "                    question = row.get(\"question\", row.get(\"Question\", \"\")).strip().strip('\"')\n",
    "                    answer = row.get(\"answer\", row.get(\"Answer\", \"\")).strip().strip('\"')\n",
    "                    category = row.get(\"category\", \"general\")\n",
    "                    hospital = row.get(\"hospital\", \"both\")\n",
    "                    \n",
    "                    self.qa_pairs.append({\n",
    "                        \"question\": question, \n",
    "                        \"answer\": answer,\n",
    "                        \"category\": category,\n",
    "                        \"hospital\": hospital\n",
    "                    })\n",
    "                    # Add to context for the model\n",
    "                    self.context_data += f\"Q: {question}\\nA: {answer}\\n\\n\"\n",
    "            \n",
    "            print(f\"Loaded {len(self.qa_pairs)} medical Q&A pairs from hospital dataset\")\n",
    "            \n",
    "            # Set original count for learning statistics\n",
    "            self.original_qa_count = len(self.qa_pairs)\n",
    "            \n",
    "            # Create TF-IDF vectors for ML-enhanced matching\n",
    "            self.create_qa_vectors()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Q&A data: {e}\")\n",
    "            \n",
    "    def create_qa_vectors(self):\n",
    "        \"\"\"Create TF-IDF vectors for all Q&A pairs for semantic matching\"\"\"\n",
    "        try:\n",
    "            if self.vectorizer and self.qa_pairs:\n",
    "                questions = [qa[\"question\"] for qa in self.qa_pairs]\n",
    "                self.qa_vectors = self.vectorizer.fit_transform(questions)\n",
    "                print(\"Created TF-IDF vectors for semantic matching\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create vectors: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416b009",
   "metadata": {},
   "source": [
    "## Semantic Understanding with Sentence Transformers\n",
    "\n",
    "Advanced semantic similarity matching using state-of-the-art sentence transformers for better understanding of medical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a86e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_semantic_embeddings(self):\n",
    "        \"\"\"Create semantic embeddings for all Q&A pairs\"\"\"\n",
    "        try:\n",
    "            if not self.sentence_transformer:\n",
    "                return\n",
    "                \n",
    "            # Create embeddings for questions and answers\n",
    "            questions = [qa['question'] for qa in self.qa_pairs]\n",
    "            answers = [qa['answer'] for qa in self.qa_pairs]\n",
    "            \n",
    "            print(\"Creating semantic embeddings...\")\n",
    "            self.question_embeddings = self.sentence_transformer.encode(questions)\n",
    "            self.answer_embeddings = self.sentence_transformer.encode(answers)\n",
    "            \n",
    "            print(f\"✓ Created embeddings for {len(questions)} Q&A pairs\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating semantic embeddings: {e}\")\n",
    "    \n",
    "    def get_semantic_answer(self, user_input, intent):\n",
    "        \"\"\"Get answer using semantic similarity with sentence transformers\"\"\"\n",
    "        try:\n",
    "            if not self.sentence_transformer or not hasattr(self, 'question_embeddings'):\n",
    "                return None\n",
    "            \n",
    "            # Encode the user input\n",
    "            user_embedding = self.sentence_transformer.encode([user_input])\n",
    "            \n",
    "            # Calculate semantic similarity with questions\n",
    "            similarities = np.dot(user_embedding, self.question_embeddings.T).flatten()\n",
    "            \n",
    "            # Find best matches\n",
    "            best_indices = np.argsort(similarities)[::-1][:3]\n",
    "            best_scores = similarities[best_indices]\n",
    "            \n",
    "            # Check if best match is semantically similar (threshold of 0.3)\n",
    "            if best_scores[0] > 0.3:\n",
    "                best_match = self.qa_pairs[best_indices[0]]\n",
    "                \n",
    "                # Generate contextual response based on intent\n",
    "                enhanced_answer = self.enhance_answer_with_intent(\n",
    "                    best_match['answer'], intent, user_input\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    'answer': enhanced_answer,\n",
    "                    'confidence': float(best_scores[0]),\n",
    "                    'source': 'semantic_nlp',\n",
    "                    'intent': intent,\n",
    "                    'method': 'sentence_transformer'\n",
    "                }\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in semantic answer generation: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4cbe0",
   "metadata": {},
   "source": [
    "## Dynamic Answer Generation\n",
    "\n",
    "Intelligent response generation based on medical intents including appointments, pricing, emergency contacts, and hospital services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3af6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generate_dynamic_answer(self, user_input, intent):\n",
    "        \"\"\"Generate dynamic answers based on intent and medical domain knowledge\"\"\"\n",
    "        \n",
    "        # Extract key entities from user input\n",
    "        entities = self.extract_entities(user_input)\n",
    "        \n",
    "        # Generate intent-specific responses\n",
    "        if intent == 'appointment':\n",
    "            return self.generate_appointment_response(entities, user_input)\n",
    "        \n",
    "        elif intent == 'pricing':\n",
    "            return self.generate_pricing_response(entities, user_input)\n",
    "        \n",
    "        elif intent == 'hospital_info':\n",
    "            return self.generate_hospital_info_response(entities, user_input)\n",
    "        \n",
    "        elif intent == 'emergency':\n",
    "            return self.generate_emergency_response(entities, user_input)\n",
    "        \n",
    "        elif intent == 'departments':\n",
    "            return self.generate_departments_response(entities, user_input)\n",
    "        \n",
    "        elif intent == 'insurance':\n",
    "            return self.generate_insurance_response(user_input)\n",
    "        \n",
    "        elif intent == 'medical_records':\n",
    "            return self.generate_medical_records_response(user_input)\n",
    "        \n",
    "        elif intent == 'symptoms':\n",
    "            return self.generate_symptoms_response(entities, user_input)\n",
    "        \n",
    "        elif intent == 'pharmacy':\n",
    "            return self.generate_pharmacy_response(user_input)\n",
    "        \n",
    "        elif intent == 'general':\n",
    "            return self.generate_general_response(user_input)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca2138",
   "metadata": {},
   "source": [
    "## Medical Response Generators\n",
    "\n",
    "Specialized response generators for different medical service categories providing accurate and helpful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generate_appointment_response(self, entities, user_input):\n",
    "        \"\"\"Generate appointment booking responses\"\"\"\n",
    "        return {\n",
    "            'answer': \"To book an appointment: Nairobi Hospital: +254-20-2845000 or online portal. Kenyatta National Hospital: +254-20-2726300. For specialists, please book 2-3 days in advance. Emergency services available 24/7.\",\n",
    "            'confidence': 0.8,\n",
    "            'source': 'dynamic_generation',\n",
    "            'intent': 'appointment',\n",
    "            'method': 'template_based'\n",
    "        }\n",
    "    \n",
    "    def generate_emergency_response(self, entities, user_input):\n",
    "        \"\"\"Generate emergency contact responses\"\"\"\n",
    "        return {\n",
    "            'answer': \"EMERGENCY CONTACTS: Nairobi Hospital: +254-20-2845000 | Kenyatta National: +254-20-2726300 | Both hospitals operate 24/7 emergency services. For life-threatening situations, call immediately.\",\n",
    "            'confidence': 0.9,\n",
    "            'source': 'dynamic_generation',\n",
    "            'intent': 'emergency',\n",
    "            'method': 'template_based'\n",
    "        }\n",
    "    \n",
    "    def generate_pricing_response(self, entities, user_input):\n",
    "        \"\"\"Generate dynamic medical pricing responses\"\"\"\n",
    "        return {\n",
    "            'answer': \"Medical service pricing varies by procedure and hospital. General ranges: CT scan 8,000-25,000 KSh, Normal delivery 25,000-120,000 KSh, C-section 60,000-200,000 KSh. Insurance coverage available. Contact billing for specific procedures.\",\n",
    "            'confidence': 0.7,\n",
    "            'source': 'dynamic_generation',\n",
    "            'intent': 'pricing',\n",
    "            'method': 'template_based'\n",
    "        }\n",
    "    \n",
    "    def generate_departments_response(self, entities, user_input):\n",
    "        \"\"\"Generate department information responses\"\"\"\n",
    "        return {\n",
    "            'answer': \"Available departments: Cardiology, Neurology, Oncology, Pediatrics, Orthopedics, Radiology, Emergency Medicine, Maternity, Surgery, Internal Medicine, Psychiatry, Dermatology, and more. Specialist appointments available.\",\n",
    "            'confidence': 0.8,\n",
    "            'source': 'dynamic_generation',\n",
    "            'intent': 'departments',\n",
    "            'method': 'template_based'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09243852",
   "metadata": {},
   "source": [
    "## Machine Learning Fallback System\n",
    "\n",
    "TF-IDF based similarity matching as a fallback when advanced NLP methods are not available or don't produce confident results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def initialize_fallback_ml(self):\n",
    "        \"\"\"Fallback ML initialization if advanced NLP fails\"\"\"\n",
    "        try:\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "            from sklearn.metrics.pairwise import cosine_similarity\n",
    "            \n",
    "            print(\"Initializing fallback ML components...\")\n",
    "            \n",
    "            # Initialize TF-IDF vectorizer for semantic matching\n",
    "            self.vectorizer = TfidfVectorizer(\n",
    "                max_features=1000,\n",
    "                stop_words='english',\n",
    "                ngram_range=(1, 2)\n",
    "            )\n",
    "            \n",
    "            # Load conversation history if exists\n",
    "            self.load_conversation_history()\n",
    "            \n",
    "            # Load feedback scores if exists\n",
    "            self.load_feedback_scores()\n",
    "            \n",
    "            print(\"ML components initialized successfully\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"WARNING: scikit-learn not available. Using basic matching.\")\n",
    "            self.vectorizer = None\n",
    "    \n",
    "    def get_ml_context_answer(self, user_input):\n",
    "        \"\"\"Fallback ML method for enhanced context matching\"\"\"\n",
    "        if not self.qa_pairs or not self.vectorizer or self.qa_vectors is None:\n",
    "            return self.get_basic_context_answer(user_input)\n",
    "            \n",
    "        try:\n",
    "            from sklearn.metrics.pairwise import cosine_similarity\n",
    "            \n",
    "            # Vectorize user input\n",
    "            user_vector = self.vectorizer.transform([user_input])\n",
    "            \n",
    "            # Calculate cosine similarity with all Q&A pairs\n",
    "            similarities = cosine_similarity(user_vector, self.qa_vectors).flatten()\n",
    "            \n",
    "            # Find best matches\n",
    "            best_indices = np.argsort(similarities)[::-1][:3]  # Top 3 matches\n",
    "            best_scores = similarities[best_indices]\n",
    "            \n",
    "            # Check if best match is good enough (threshold of 0.1)\n",
    "            if best_scores[0] > 0.1:\n",
    "                best_match = self.qa_pairs[best_indices[0]]\n",
    "                \n",
    "                return {\n",
    "                    'answer': best_match['answer'],\n",
    "                    'confidence': min(best_scores[0] * 2, 1.0),  # Scale to 0-1\n",
    "                    'source': 'ml_context',\n",
    "                    'method': 'tfidf_cosine_similarity'\n",
    "                }\n",
    "                \n",
    "        except ImportError:\n",
    "            return self.get_basic_context_answer(user_input)\n",
    "        except Exception as e:\n",
    "            print(f\"ML matching error: {e}\")\n",
    "            return self.get_basic_context_answer(user_input)\n",
    "            \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2f4e3",
   "metadata": {},
   "source": [
    "## Flask API Endpoints\n",
    "\n",
    "Production-ready REST API endpoints for the hospital chatbot system with comprehensive functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chatbot - make CSV path optional since we're using pretrained model\n",
    "csv_path = \"../data/hospital_comprehensive_data.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    print(f\"Warning: CSV file not found at {csv_path}. Using pretrained model only.\")\n",
    "    csv_path = None\n",
    "\n",
    "chatbot = NLPEnhancedChatbot(csv_path)\n",
    "\n",
    "# Root route for basic info\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return jsonify({\n",
    "        \"message\": \"Hospital AI Agent Backend is running!\",\n",
    "        \"endpoints\": {\n",
    "            \"chat\": \"/chat (POST)\",\n",
    "            \"health\": \"/health (GET)\", \n",
    "            \"stats\": \"/stats (GET)\"\n",
    "        },\n",
    "        \"qa_pairs_loaded\": len(chatbot.qa_pairs)\n",
    "    })\n",
    "\n",
    "# API endpoint for chatbot\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    try:\n",
    "        data = request.json\n",
    "        user_message = data.get(\"message\", \"\").strip()\n",
    "        \n",
    "        if not user_message:\n",
    "            return jsonify({\"error\": \"No message provided\"}), 400\n",
    "        \n",
    "        response_data = chatbot.get_response(user_message)\n",
    "        \n",
    "        return jsonify({\n",
    "            \"response\": response_data[\"response\"],\n",
    "            \"confidence\": response_data[\"confidence\"],\n",
    "            \"source\": response_data[\"source\"],\n",
    "            \"status\": \"success\"\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            \"error\": str(e),\n",
    "            \"status\": \"error\"\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint with model loading status\"\"\"\n",
    "    if chatbot.model_loading:\n",
    "        model_status = f\"Loading... ({chatbot.model_type})\"\n",
    "    elif hasattr(chatbot, 'model') and chatbot.model is not None:\n",
    "        model_status = chatbot.model_type\n",
    "    else:\n",
    "        model_status = chatbot.model_type\n",
    "    \n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\",\n",
    "        \"qa_pairs_loaded\": len(chatbot.qa_pairs),\n",
    "        \"model_type\": model_status,\n",
    "        \"model_loading\": chatbot.model_loading,\n",
    "        \"context_available\": len(chatbot.context_data) > 0\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a92200",
   "metadata": {},
   "source": [
    "## Server Startup and Testing\n",
    "\n",
    "Start the Flask development server for testing the chatbot API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chatbot initialization\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Hospital AI Chatbot Backend - Notebook Version\")\n",
    "    print(f\"Loaded {len(chatbot.qa_pairs)} Q&A pairs as context\")\n",
    "    print(\"AI model loading in background...\")\n",
    "    print(\"Ready for testing!\")\n",
    "    \n",
    "    # Test a sample query\n",
    "    sample_response = chatbot.get_response(\"How do I book an appointment?\")\n",
    "    print(\"\\nSample Query Test:\")\n",
    "    print(f\"Response: {sample_response['response']}\")\n",
    "    print(f\"Confidence: {sample_response['confidence']}\")\n",
    "    print(f\"Source: {sample_response['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00fb40",
   "metadata": {},
   "source": [
    "## Manual Testing Interface\n",
    "\n",
    "Interactive testing cell for manually testing the chatbot responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing function\n",
    "def test_chatbot_query(query):\n",
    "    \"\"\"Test a specific query with the chatbot\"\"\"\n",
    "    print(f\"Query: {query}\")\n",
    "    response = chatbot.get_response(query)\n",
    "    print(f\"Response: {response['response']}\")\n",
    "    print(f\"Confidence: {response['confidence']:.3f}\")\n",
    "    print(f\"Source: {response['source']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Test various medical queries\n",
    "test_queries = [\n",
    "    \"What are the emergency contact numbers?\",\n",
    "    \"How much does a CT scan cost?\",\n",
    "    \"What departments are available?\",\n",
    "    \"How do I get my medical records?\",\n",
    "    \"Hello, I need help\"\n",
    "]\n",
    "\n",
    "print(\"Testing Hospital AI Chatbot:\")\n",
    "print(\"=\" * 50)\n",
    "for query in test_queries:\n",
    "    test_chatbot_query(query)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
